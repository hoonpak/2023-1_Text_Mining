{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:51:13.338082Z","iopub.status.busy":"2023-06-07T04:51:13.337772Z","iopub.status.idle":"2023-06-07T04:51:25.311162Z","shell.execute_reply":"2023-06-07T04:51:25.309941Z","shell.execute_reply.started":"2023-06-07T04:51:13.338056Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.29.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (5.4.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.5.5)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:51:25.315684Z","iopub.status.busy":"2023-06-07T04:51:25.315259Z","iopub.status.idle":"2023-06-07T04:51:39.154624Z","shell.execute_reply":"2023-06-07T04:51:39.153472Z","shell.execute_reply.started":"2023-06-07T04:51:25.315648Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"]}],"source":["import tensorflow as tf\n","import torch\n","\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from torch import nn\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","import random\n","import time\n","import datetime"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:51:39.156552Z","iopub.status.busy":"2023-06-07T04:51:39.156207Z","iopub.status.idle":"2023-06-07T04:51:39.518737Z","shell.execute_reply":"2023-06-07T04:51:39.517585Z","shell.execute_reply.started":"2023-06-07T04:51:39.156520Z"},"trusted":true},"outputs":[],"source":["data = pd.read_csv(\"/kaggle/input/trip-advisor-hotel-reviews/tripadvisor_hotel_reviews.csv\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:51:39.527257Z","iopub.status.busy":"2023-06-07T04:51:39.525190Z","iopub.status.idle":"2023-06-07T04:51:39.542691Z","shell.execute_reply":"2023-06-07T04:51:39.541737Z","shell.execute_reply.started":"2023-06-07T04:51:39.527227Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Review</th>\n","      <th>Rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>nice hotel expensive parking got good deal sta...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ok nothing special charge diamond member hilto...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>nice rooms not 4* experience hotel monaco seat...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>unique, great stay, wonderful time hotel monac...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>great stay great stay, went seahawk game aweso...</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              Review  Rating\n","0  nice hotel expensive parking got good deal sta...       4\n","1  ok nothing special charge diamond member hilto...       2\n","2  nice rooms not 4* experience hotel monaco seat...       3\n","3  unique, great stay, wonderful time hotel monac...       5\n","4  great stay great stay, went seahawk game aweso...       5"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:51:39.544961Z","iopub.status.busy":"2023-06-07T04:51:39.544332Z","iopub.status.idle":"2023-06-07T04:51:39.551102Z","shell.execute_reply":"2023-06-07T04:51:39.550168Z","shell.execute_reply.started":"2023-06-07T04:51:39.544928Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(20491, 2)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["data.shape"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:51:39.553308Z","iopub.status.busy":"2023-06-07T04:51:39.552694Z","iopub.status.idle":"2023-06-07T04:51:39.760204Z","shell.execute_reply":"2023-06-07T04:51:39.759210Z","shell.execute_reply.started":"2023-06-07T04:51:39.553276Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0., 0., 0., 1., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 0., 1., 0., 0.],\n","        ...,\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.]])\n"]}],"source":["import torch\n","\n","# 클래스 레이블\n","labels = data['Rating']\n","\n","# 클래스의 개수\n","num_classes = max(labels) + 1\n","\n","# 원-핫 인코딩\n","onehot_labels = torch.eye(num_classes)[data['Rating']]\n","onehot_labels = onehot_labels[:, 1:]\n","print(onehot_labels)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:51:39.762221Z","iopub.status.busy":"2023-06-07T04:51:39.761626Z","iopub.status.idle":"2023-06-07T04:51:39.969547Z","shell.execute_reply":"2023-06-07T04:51:39.968587Z","shell.execute_reply.started":"2023-06-07T04:51:39.762189Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(data['Review'], onehot_labels, test_size=0.2, stratify = onehot_labels, random_state=42)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:51:39.973446Z","iopub.status.busy":"2023-06-07T04:51:39.972540Z","iopub.status.idle":"2023-06-07T04:51:39.996256Z","shell.execute_reply":"2023-06-07T04:51:39.995329Z","shell.execute_reply.started":"2023-06-07T04:51:39.973411Z"},"trusted":true},"outputs":[],"source":["# BERT의 입력 형식\n","sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in x_train]"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:51:39.998686Z","iopub.status.busy":"2023-06-07T04:51:39.997850Z","iopub.status.idle":"2023-06-07T04:52:41.603930Z","shell.execute_reply":"2023-06-07T04:52:41.603003Z","shell.execute_reply.started":"2023-06-07T04:51:39.998620Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d70aec4832b2415bb96c6d236efa0250","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd799c9fe0de4d77ab6e81161e00b32a","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30d4946cb9d643eeb404799c2546113d","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["100%|██████████| 16392/16392 [01:00<00:00, 270.27it/s]"]},{"name":"stdout","output_type":"stream","text":["[CLS] san francisco charm stay san francisco frequently business, tried joie vivre hotels love old world charm elegance, rex great, small staff knows conviences needed i.e. restaurant lobby bar internet large clean rooms welcoming staff, right corner union square, stay want charm old san francisco,   [SEP]\n","['[CLS]', 'san', 'francisco', 'charm', 'stay', 'san', 'francisco', 'frequently', 'business', ',', 'tried', 'jo', '##ie', 'vi', '##vre', 'hotels', 'love', 'old', 'world', 'charm', 'elegance', ',', 'rex', 'great', ',', 'small', 'staff', 'knows', 'con', '##vie', '##nce', '##s', 'needed', 'i', '.', 'e', '.', 'restaurant', 'lobby', 'bar', 'internet', 'large', 'clean', 'rooms', 'welcoming', 'staff', ',', 'right', 'corner', 'union', 'square', ',', 'stay', 'want', 'charm', 'old', 'san', 'francisco', ',', '[SEP]']\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# BERT 토크나이저로 문장을 토큰화\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in tqdm(sentences)]\n","\n","print (sentences[0])\n","print (tokenized_texts[0])"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:53:38.476618Z","iopub.status.busy":"2023-06-07T04:53:38.476246Z","iopub.status.idle":"2023-06-07T04:53:41.801785Z","shell.execute_reply":"2023-06-07T04:53:41.800776Z","shell.execute_reply.started":"2023-06-07T04:53:38.476587Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 16392/16392 [00:03<00:00, 5421.33it/s]\n"]},{"data":{"text/plain":["array([  101,  2624,  3799, 11084,  2994,  2624,  3799,  4703,  2449,\n","        1010,  2699,  8183,  2666,  6819, 12229,  9275,  2293,  2214,\n","        2088, 11084, 27745,  1010, 10151,  2307,  1010,  2235,  3095,\n","        4282,  9530, 13469,  5897,  2015,  2734,  1045,  1012,  1041,\n","        1012,  4825,  9568,  3347,  4274,  2312,  4550,  4734, 18066,\n","        3095,  1010,  2157,  3420,  2586,  2675,  1010,  2994,  2215,\n","       11084,  2214,  2624,  3799,  1010,   102,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# 입력 최대 토큰 개수\n","MAX_LEN = 128\n","\n","# 토큰을 id로 변환\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tqdm(tokenized_texts)]\n","\n","# 패딩\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","input_ids[0]"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:53:41.804180Z","iopub.status.busy":"2023-06-07T04:53:41.803745Z","iopub.status.idle":"2023-06-07T04:53:43.205127Z","shell.execute_reply":"2023-06-07T04:53:43.204232Z","shell.execute_reply.started":"2023-06-07T04:53:41.804147Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 16392/16392 [00:01<00:00, 11785.57it/s]"]},{"name":"stdout","output_type":"stream","text":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["attention_masks = []\n","\n","# attention mask if padding = 0; 1\n","for seq in tqdm(input_ids):\n","    seq_mask = [int(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","print(attention_masks[0])"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:53:43.207360Z","iopub.status.busy":"2023-06-07T04:53:43.206536Z","iopub.status.idle":"2023-06-07T04:53:43.953491Z","shell.execute_reply":"2023-06-07T04:53:43.952554Z","shell.execute_reply.started":"2023-06-07T04:53:43.207324Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([  101,  2307,  2994, 10931,  3309,  4370, 10931,  1017,  6385, 19227,\n","         1010, 17414,  3495,  3309,  3446, 14210,  2692, 22563,  2094,  2305,\n","        15203,  7440,  3193,  2282,  1010,  4638,  1011,  1999,  3733,  2288,\n","         9725,  7621,  2282, 19227,  1010,  2489,  5835, 12327, 10931,  6945,\n","        18389,  5909,  7967,  2015,  2994,  2428,  2569,  1010,  3193,  7440,\n","         2204,  2275, 16317, 27208,  3121,  2215,  2488,  3193,  2994,  3309,\n","        16317,  1010,  9690,  2106,  1050,  1005,  1056,  2644,  9107,  3193,\n","         4597, 14406,  3121,  2422,  1010,  4734, 12176,  2154,  2326,  7884,\n","         2204,  1010,  8823,  3585,  7053,  2822,  3095, 14044, 16755,  2075,\n","        10447,  2648,  2379,  4770,  2181,  5337,  1010,  2106,  1050,  1005,\n","         1056,  2338,  7562,  3309,  2074,  2253,  7564, 25964,  2648,  3309,\n","        16286, 21125,  1010, 12246,  5632,  2994, 16755,  3309,  1010,  4102,\n","         1019,  1008,  9275,  2204,  3976,  2828,  2282, 17414])\n","tensor([0., 0., 0., 0., 1.])\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0.])\n","tensor([  101,  2307,  3309,  6581,  2326,  2074,  2513,  1019,  2154,  2994,\n","         5264,  4370,  2548,  8232,  3660,  2015,  1010,  2307,  3295,  2485,\n","         7340, 11047,  2099,  5983,  3182,  1010,  3309,  6581,  2282,  2204,\n","         2210,  9364,  2053,  7198,  2312,  6457,  3123,  2023,  1012,  3095,\n","         5379,  2326,  6581,  1010, 28305,  6350,  2190,  1010,  3944, 28305,\n","         3811,  6758,  1010,  5264,  5798,  3264,  3095,  2266,  2246, 19494,\n","         7039,  1010,  5798,  3369,  2282,  2383,  4596,  5798,  9850, 13541,\n","         4003,  3403,  1010, 16082,  1010,  3835,  9218,  1010,  5121,  2994,\n","         2925,  1010,   102,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0])\n","tensor([0., 0., 0., 0., 1.])\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0.])\n"]}],"source":["train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n","                                                                                    np.array(y_train), \n","                                                                                    random_state=2018,\n","                                                                                    stratify = y_train,\n","                                                                                    test_size=0.1)\n","\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n","                                                       input_ids,\n","                                                       random_state=2018, \n","                                                       test_size=0.1)\n","\n","# 파이토치의 텐서로 변환\n","train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_inputs = torch.tensor(validation_inputs)\n","validation_labels = torch.tensor(validation_labels)\n","validation_masks = torch.tensor(validation_masks)\n","\n","print(train_inputs[0])\n","print(train_labels[0])\n","print(train_masks[0])\n","print(validation_inputs[0])\n","print(validation_labels[0])\n","print(validation_masks[0])"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:53:43.957067Z","iopub.status.busy":"2023-06-07T04:53:43.955408Z","iopub.status.idle":"2023-06-07T04:53:43.963234Z","shell.execute_reply":"2023-06-07T04:53:43.962267Z","shell.execute_reply.started":"2023-06-07T04:53:43.957030Z"},"trusted":true},"outputs":[],"source":["batch_size = 32\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:54:07.550463Z","iopub.status.busy":"2023-06-07T04:54:07.549729Z","iopub.status.idle":"2023-06-07T04:54:23.444832Z","shell.execute_reply":"2023-06-07T04:54:23.443848Z","shell.execute_reply.started":"2023-06-07T04:54:07.550428Z"},"trusted":true},"outputs":[],"source":["# BERT 입력 형식\n","sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in x_test]\n","\n","labels = np.array(y_test)\n","\n","# 토큰화\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","MAX_LEN = 128\n","\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","attention_masks = []\n","\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","    \n","test_inputs = torch.tensor(input_ids)\n","test_labels = torch.tensor(labels)\n","test_masks = torch.tensor(attention_masks)\n","\n","batch_size = 32\n","\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:54:23.447230Z","iopub.status.busy":"2023-06-07T04:54:23.446870Z","iopub.status.idle":"2023-06-07T04:54:28.353411Z","shell.execute_reply":"2023-06-07T04:54:28.352363Z","shell.execute_reply.started":"2023-06-07T04:54:23.447198Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found GPU at: /device:GPU:0\n"]}],"source":["# GPU 디바이스 이름\n","device_name = tf.test.gpu_device_name()\n","\n","# GPU 검사\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:54:28.355626Z","iopub.status.busy":"2023-06-07T04:54:28.355009Z","iopub.status.idle":"2023-06-07T04:54:28.376463Z","shell.execute_reply":"2023-06-07T04:54:28.375461Z","shell.execute_reply.started":"2023-06-07T04:54:28.355592Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}],"source":["# 디바이스 설정\n","if torch.cuda.is_available():    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using the CPU instead.')"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:54:28.380545Z","iopub.status.busy":"2023-06-07T04:54:28.380020Z","iopub.status.idle":"2023-06-07T04:54:31.236474Z","shell.execute_reply":"2023-06-07T04:54:31.235525Z","shell.execute_reply.started":"2023-06-07T04:54:28.380513Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1586215daf294264a7f0bf7dbbfa48f7","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",")"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# 분류를 위한 BERT 모델 생성\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=5, problem_type=\"multi_label_classification\")\n","model.cuda()"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:55:51.662438Z","iopub.status.busy":"2023-06-07T04:55:51.662074Z","iopub.status.idle":"2023-06-07T04:55:51.674270Z","shell.execute_reply":"2023-06-07T04:55:51.673339Z","shell.execute_reply.started":"2023-06-07T04:55:51.662409Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5,\n","                  eps = 1e-8 # 0으로 나누는 것을 방지\n","                 )\n","\n","epochs = 4\n","\n","# 총 훈련 스텝 = 배치 수 * 에폭\n","total_steps = len(train_dataloader) * epochs\n","\n","#스케줄러\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:55:53.039336Z","iopub.status.busy":"2023-06-07T04:55:53.038653Z","iopub.status.idle":"2023-06-07T04:55:53.044947Z","shell.execute_reply":"2023-06-07T04:55:53.043955Z","shell.execute_reply.started":"2023-06-07T04:55:53.039300Z"},"trusted":true},"outputs":[],"source":["def flat_accuracy(preds, labels):\n","    \n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = np.argmax(labels, axis=1).flatten()\n","\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:55:53.698081Z","iopub.status.busy":"2023-06-07T04:55:53.695988Z","iopub.status.idle":"2023-06-07T04:55:53.704955Z","shell.execute_reply":"2023-06-07T04:55:53.703719Z","shell.execute_reply.started":"2023-06-07T04:55:53.698037Z"},"trusted":true},"outputs":[],"source":["# 시간 표시 함수\n","def format_time(elapsed):\n","\n","    # 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # hh:mm:ss으로 형태 변경\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:55:54.371984Z","iopub.status.busy":"2023-06-07T04:55:54.371596Z","iopub.status.idle":"2023-06-07T05:07:25.266976Z","shell.execute_reply":"2023-06-07T05:07:25.266016Z","shell.execute_reply.started":"2023-06-07T04:55:54.371950Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 461/461 [02:47<00:00,  2.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","  Average training loss: 0.36\n","  Training epcoh took: 0:02:48\n","\n","Running Validation...\n","  Accuracy: 0.63\n","  Validation took: 0:00:06\n","\n","======== Epoch 2 / 4 ========\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 461/461 [02:46<00:00,  2.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","  Average training loss: 0.28\n","  Training epcoh took: 0:02:47\n","\n","Running Validation...\n","  Accuracy: 0.67\n","  Validation took: 0:00:06\n","\n","======== Epoch 3 / 4 ========\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 461/461 [02:46<00:00,  2.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","  Average training loss: 0.25\n","  Training epcoh took: 0:02:47\n","\n","Running Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:06\n","\n","======== Epoch 4 / 4 ========\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 461/461 [02:46<00:00,  2.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","  Average training loss: 0.22\n","  Training epcoh took: 0:02:47\n","\n","Running Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:06\n","\n","Training complete!\n"]}],"source":["# fix randomseed\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","model.zero_grad()\n","\n","for epoch_i in range(0, epochs):\n","    \n","    #Training\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    t0 = time.time()\n","\n","    total_loss = 0\n","\n","    model.train()\n","        \n","    for step, batch in enumerate(tqdm(train_dataloader)):\n","\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask, \n","                        labels=b_labels)\n","        \n","        loss = outputs.loss\n","        total_loss += loss.item()\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        scheduler.step()\n","        model.zero_grad()\n","\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","        \n","    #Validation\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    model.eval()\n","\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    for batch in validation_dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        with torch.no_grad():     \n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        logits = outputs.logits\n","\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy\n","        nb_eval_steps += 1\n","\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T05:07:25.269199Z","iopub.status.busy":"2023-06-07T05:07:25.268859Z","iopub.status.idle":"2023-06-07T05:07:39.797500Z","shell.execute_reply":"2023-06-07T05:07:39.796596Z","shell.execute_reply.started":"2023-06-07T05:07:25.269167Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 129/129 [00:14<00:00,  8.89it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy: 0.67\n","Test took: 0:00:15\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["t0 = time.time()\n","\n","model.eval()\n","\n","eval_loss = 0\n","eval_accuracy = 0\n","nb_eval_steps = 0\n","nb_eval_examples = 0\n","\n","for step, batch in enumerate(tqdm(test_dataloader)):\n","    \n","    batch = tuple(t.to(device) for t in batch)\n","    \n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    with torch.no_grad():     \n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","    \n","    logits = outputs.logits\n","\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    \n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","    eval_accuracy += tmp_eval_accuracy\n","    nb_eval_steps += 1\n","\n","print(\"\")\n","print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","print(\"Test took: {:}\".format(format_time(time.time() - t0)))"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T05:07:39.799745Z","iopub.status.busy":"2023-06-07T05:07:39.799289Z","iopub.status.idle":"2023-06-07T05:07:39.807779Z","shell.execute_reply":"2023-06-07T05:07:39.806723Z","shell.execute_reply.started":"2023-06-07T05:07:39.799706Z"},"trusted":true},"outputs":[],"source":["def convert_input_data(sentences):\n","\n","    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","    MAX_LEN = 128\n","\n","    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","    attention_masks = []\n","\n","    for seq in input_ids:\n","        seq_mask = [float(i>0) for i in seq]\n","        attention_masks.append(seq_mask)\n","\n","    inputs = torch.tensor(input_ids)\n","    masks = torch.tensor(attention_masks)\n","\n","    return inputs, masks"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T05:07:39.811471Z","iopub.status.busy":"2023-06-07T05:07:39.810695Z","iopub.status.idle":"2023-06-07T05:07:39.822922Z","shell.execute_reply":"2023-06-07T05:07:39.821773Z","shell.execute_reply.started":"2023-06-07T05:07:39.811410Z"},"trusted":true},"outputs":[],"source":["def test_sentences(sentences):\n","\n","    model.eval()\n","\n","    inputs, masks = convert_input_data(sentences)\n","\n","    b_input_ids = inputs.to(device)\n","    b_input_mask = masks.to(device)\n","            \n","    with torch.no_grad():     \n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","\n","    logits = outputs.logits\n","    logits = logits.detach().cpu().numpy()\n","\n","    return logits"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T05:16:34.924908Z","iopub.status.busy":"2023-06-07T05:16:34.923870Z","iopub.status.idle":"2023-06-07T05:16:37.984248Z","shell.execute_reply":"2023-06-07T05:16:37.983124Z","shell.execute_reply.started":"2023-06-07T05:16:34.924867Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" \"Nice hotel, no major complaints: (1) some of the furnishings in the room could use some updating (worn areas on the sofa, etc). and (2) Breakfast buffet had a lot of options, but surprisingly few gluten-free ones (would be great to have things like waffles, baked goods like muffins). Staff are very attentive and they helped us find some good off-the-beaten path restaurants.\"\n"]},{"name":"stdout","output_type":"stream","text":["===================================\n","[[-5.1121035  -3.82513    -1.6346102   0.37617612 -1.6418087 ]]\n","\n","본 리뷰는 4 점으로 예측됩니다.\n","===================================\n"]}],"source":["#4점 리뷰\n","review = input()\n","logits = test_sentences([review])\n","rating = np.argmax(logits)+1\n","print(\"===================================\")\n","print(logits)\n","print()\n","print(f\"본 리뷰는 {rating} 점으로 예측됩니다.\")\n","print(\"===================================\")"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T05:17:44.948419Z","iopub.status.busy":"2023-06-07T05:17:44.947718Z","iopub.status.idle":"2023-06-07T05:17:52.867941Z","shell.execute_reply":"2023-06-07T05:17:52.866943Z","shell.execute_reply.started":"2023-06-07T05:17:44.948384Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" Klook is the worst transportation website I have ever booked from airport to hotel. We had to leave the airport to go out in the wet cold night to the pick up Point. I nearly fell from the slippery floor trying to look for the car and pick up point at 8 pm. The driver did not drop us off at the main hotel lobby. He dropped us off at an unknown place saying the front entrance is behind the boom gate at the end of the street. It turned out to be a shopping mall at the end of the street. We asked other pedestrians and they told us to walk back out of the street into another street and walk uphill. For the first time I had to walk uphill with my family with 5 luggages to reach the closest entrance which was the back of the hotel. We complained to the company and they did not do anything. They promised to look into the matter and I found I was crossed out of their communication system. This is definite not a reliable company. I normally don’t write many reviews but when I write I write with the intention that people will not suffer what I have been through\n"]},{"name":"stdout","output_type":"stream","text":["===================================\n","[[ 1.1867468 -1.3499482 -3.5678453 -3.8017917 -3.7586148]]\n","\n","본 리뷰는 1 점으로 예측됩니다.\n","===================================\n"]}],"source":["#1점 리뷰\n","review = input()\n","logits = test_sentences([review])\n","rating = np.argmax(logits)+1\n","print(\"===================================\")\n","print(logits)\n","print()\n","print(f\"본 리뷰는 {rating} 점으로 예측됩니다.\")\n","print(\"===================================\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
